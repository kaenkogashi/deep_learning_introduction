{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Valid Cost: 1.260, Valid Accuracy: 0.665\n",
      "EPOCH: 2, Valid Cost: 1.100, Valid Accuracy: 0.727\n",
      "EPOCH: 3, Valid Cost: 1.011, Valid Accuracy: 0.765\n",
      "EPOCH: 4, Valid Cost: 0.944, Valid Accuracy: 0.791\n",
      "EPOCH: 5, Valid Cost: 0.899, Valid Accuracy: 0.800\n",
      "EPOCH: 6, Valid Cost: 0.868, Valid Accuracy: 0.811\n",
      "EPOCH: 7, Valid Cost: 0.831, Valid Accuracy: 0.814\n",
      "EPOCH: 8, Valid Cost: 0.804, Valid Accuracy: 0.819\n",
      "EPOCH: 9, Valid Cost: 0.785, Valid Accuracy: 0.820\n",
      "EPOCH: 10, Valid Cost: 0.765, Valid Accuracy: 0.837\n",
      "EPOCH: 11, Valid Cost: 0.743, Valid Accuracy: 0.849\n",
      "EPOCH: 12, Valid Cost: 0.728, Valid Accuracy: 0.845\n",
      "EPOCH: 13, Valid Cost: 0.711, Valid Accuracy: 0.850\n",
      "EPOCH: 14, Valid Cost: 0.695, Valid Accuracy: 0.853\n",
      "EPOCH: 15, Valid Cost: 0.680, Valid Accuracy: 0.848\n",
      "EPOCH: 16, Valid Cost: 0.663, Valid Accuracy: 0.859\n",
      "EPOCH: 17, Valid Cost: 0.653, Valid Accuracy: 0.857\n",
      "EPOCH: 18, Valid Cost: 0.648, Valid Accuracy: 0.859\n",
      "EPOCH: 19, Valid Cost: 0.638, Valid Accuracy: 0.862\n",
      "EPOCH: 20, Valid Cost: 0.619, Valid Accuracy: 0.863\n",
      "EPOCH: 21, Valid Cost: 0.623, Valid Accuracy: 0.864\n",
      "EPOCH: 22, Valid Cost: 0.604, Valid Accuracy: 0.867\n",
      "EPOCH: 23, Valid Cost: 0.597, Valid Accuracy: 0.867\n",
      "EPOCH: 24, Valid Cost: 0.584, Valid Accuracy: 0.869\n",
      "EPOCH: 25, Valid Cost: 0.578, Valid Accuracy: 0.870\n",
      "EPOCH: 26, Valid Cost: 0.575, Valid Accuracy: 0.867\n",
      "EPOCH: 27, Valid Cost: 0.570, Valid Accuracy: 0.872\n",
      "EPOCH: 28, Valid Cost: 0.557, Valid Accuracy: 0.878\n",
      "EPOCH: 29, Valid Cost: 0.549, Valid Accuracy: 0.877\n",
      "EPOCH: 30, Valid Cost: 0.547, Valid Accuracy: 0.879\n",
      "EPOCH: 31, Valid Cost: 0.536, Valid Accuracy: 0.879\n",
      "EPOCH: 32, Valid Cost: 0.537, Valid Accuracy: 0.879\n",
      "EPOCH: 33, Valid Cost: 0.527, Valid Accuracy: 0.878\n",
      "EPOCH: 34, Valid Cost: 0.522, Valid Accuracy: 0.878\n",
      "EPOCH: 35, Valid Cost: 0.524, Valid Accuracy: 0.875\n",
      "EPOCH: 36, Valid Cost: 0.515, Valid Accuracy: 0.881\n",
      "EPOCH: 37, Valid Cost: 0.509, Valid Accuracy: 0.884\n",
      "EPOCH: 38, Valid Cost: 0.509, Valid Accuracy: 0.884\n",
      "EPOCH: 39, Valid Cost: 0.503, Valid Accuracy: 0.880\n",
      "EPOCH: 40, Valid Cost: 0.496, Valid Accuracy: 0.887\n",
      "EPOCH: 41, Valid Cost: 0.496, Valid Accuracy: 0.888\n",
      "EPOCH: 42, Valid Cost: 0.497, Valid Accuracy: 0.888\n",
      "EPOCH: 43, Valid Cost: 0.491, Valid Accuracy: 0.885\n",
      "EPOCH: 44, Valid Cost: 0.487, Valid Accuracy: 0.889\n",
      "EPOCH: 45, Valid Cost: 0.480, Valid Accuracy: 0.888\n",
      "EPOCH: 46, Valid Cost: 0.481, Valid Accuracy: 0.884\n",
      "EPOCH: 47, Valid Cost: 0.474, Valid Accuracy: 0.893\n",
      "EPOCH: 48, Valid Cost: 0.479, Valid Accuracy: 0.889\n",
      "EPOCH: 49, Valid Cost: 0.474, Valid Accuracy: 0.887\n",
      "EPOCH: 50, Valid Cost: 0.479, Valid Accuracy: 0.882\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_fashionmnist():\n",
    "    # 学習データ\n",
    "    x_train = np.load('../dataset/x_train.npy')\n",
    "    x_train2 = x_train + np.random.rand(60000,28,28)\n",
    "    x_train = np.concatenate([x_train,x_train2])\n",
    "    y_train = np.load('../dataset/y_train.npy')\n",
    "    y_train = np.concatenate([y_train,y_train])\n",
    "    \n",
    "    # テストデータ\n",
    "    x_test = np.load('../dataset/x_test.npy')\n",
    "    \n",
    "    x_train = x_train.reshape(-1, 784).astype('float32') / 255\n",
    "    y_train = np.eye(10)[y_train.astype('int32')]\n",
    "    x_test = x_test.reshape(-1, 784).astype('float32') / 255\n",
    "    \n",
    "    return x_train, y_train, x_test\n",
    "\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "x_train, y_train, x_test = load_fashionmnist()\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=1000)\n",
    "\n",
    "#x = tf.placeholder(tf.float32, [None, 784])\n",
    "#t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "def compute_l2_reg(params):\n",
    "    l2_reg = 0\n",
    "    for param in params:\n",
    "        l2_reg += tf.reduce_sum(tf.square(param)) # 2 * tf.nn.l2_lossを使っても良い\n",
    "    return l2_reg    \n",
    "\n",
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        self.W = tf.Variable(tf.random_uniform(shape=(in_dim, out_dim), minval=-0.08, maxval=0.08), name='W')\n",
    "        self.b = tf.Variable(tf.zeros(out_dim), name='b')\n",
    "        self.function = function\n",
    "        \n",
    "        self.params = [self.W, self.b]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.function(tf.matmul(x, self.W) + self.b)\n",
    "class Dropout:\n",
    "    def __init__(self, dropout_keep_prob=1.0):\n",
    "        self.dropout_keep_prob = dropout_keep_prob\n",
    "        self.params = []\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # 訓練時のみdropoutを適用\n",
    "        return tf.cond(\n",
    "            pred=is_training,\n",
    "            true_fn=lambda: tf.nn.dropout(x, keep_prob=self.dropout_keep_prob),\n",
    "            false_fn=lambda: x\n",
    "        )\n",
    "def sgd(cost, params, eta=0.01):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        updates.append(param.assign_sub(eta * grad))\n",
    "    return updates\n",
    "\n",
    "# tf.log(0)によるnanを防ぐ\n",
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
    "\n",
    "eta = 0.01 # 学習率\n",
    "dropout_keep_prob = 0.5 # Dropout率\n",
    "lmd = 0.001 # L2正則化項の係数\n",
    "batch_size = 100 # バッチサイズ\n",
    "n_epochs = 50 # epoch数\n",
    "\n",
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 784)) # 入力データ\n",
    "t = tf.placeholder(tf.float32, (None, 10)) # 教師データ\n",
    "is_training = tf.placeholder(tf.bool) # 訓練時orテスト時\n",
    "\n",
    "layers = [\n",
    "    Dense(784, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 10, tf.nn.softmax)\n",
    "]\n",
    "\n",
    "def get_params(layers):\n",
    "    params_all = []\n",
    "    for layer in layers:\n",
    "        params = layer.params\n",
    "        params_all.extend(params)\n",
    "    return params_all\n",
    "\n",
    "def f_props(layers, h):\n",
    "    for layer in layers:\n",
    "        h = layer(h)\n",
    "    return h\n",
    "\n",
    "y = f_props(layers, x)\n",
    "params_all = get_params(layers)\n",
    "l2_reg = compute_l2_reg(params_all)\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1)) + lmd * l2_reg\n",
    "\n",
    "updates = sgd(cost, params_all, eta)\n",
    "train = tf.group(*updates)\n",
    "\n",
    "#n_epochs = 1\n",
    "#batch_size = 100\n",
    "n_batches = math.ceil(len(x_train) / batch_size)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        sess.run(train, feed_dict={x: x_train[start:end], t: y_train[start:end], is_training: True})\n",
    "    y_pred, cost_valid_ = sess.run([y, cost], feed_dict={x: x_valid, t: y_valid, is_training: False})\n",
    "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "        epoch + 1,\n",
    "        cost_valid_,\n",
    "        accuracy_score(y_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    ))\n",
    "y_pred = sess.run(y, feed_dict={x: x_test,is_training: True})\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "submission = pd.Series(y_pred, name='label')\n",
    "submission.to_csv('../dataset/submission_pred.csv', header=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
