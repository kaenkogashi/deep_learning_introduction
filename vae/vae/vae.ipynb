{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:1, Train Lower Bound:-283.150330, (-10.693234, -272.457092), Valid Lower Bound:-258.397736\n",
      "EPOCH:2, Train Lower Bound:-253.788132, (-11.842904, -241.945221), Valid Lower Bound:-250.056213\n",
      "EPOCH:3, Train Lower Bound:-248.894836, (-12.217196, -236.677643), Valid Lower Bound:-247.416046\n",
      "EPOCH:4, Train Lower Bound:-246.604431, (-12.332316, -234.272110), Valid Lower Bound:-246.351929\n",
      "EPOCH:5, Train Lower Bound:-245.134079, (-12.443249, -232.690826), Valid Lower Bound:-244.233551\n",
      "EPOCH:6, Train Lower Bound:-244.070251, (-12.529029, -231.541229), Valid Lower Bound:-243.031357\n",
      "EPOCH:7, Train Lower Bound:-243.377258, (-12.643319, -230.733932), Valid Lower Bound:-242.784134\n",
      "EPOCH:8, Train Lower Bound:-242.741028, (-12.730350, -230.010681), Valid Lower Bound:-242.617722\n",
      "EPOCH:9, Train Lower Bound:-242.193909, (-12.810193, -229.383713), Valid Lower Bound:-241.881439\n",
      "EPOCH:10, Train Lower Bound:-241.782104, (-12.884647, -228.897461), Valid Lower Bound:-241.242477\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_mnist():\n",
    "\n",
    "    # 学習データ\n",
    "    x_train = np.load('../dataset/x_train.npy')\n",
    "    \n",
    "    # テストデータ\n",
    "    x_test = np.load('../dataset/x_test.npy')\n",
    "\n",
    "    x_train = (x_train.reshape(-1, 784) / 255).astype(np.float32)\n",
    "    x_test = (x_test.reshape(-1, 784) / 255).astype(np.float32)\n",
    "\n",
    "    return (x_train, x_test)\n",
    "\n",
    "x_train, x_test = load_mnist()\n",
    "\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "\n",
    "### define layers ###\n",
    "tf.reset_default_graph()\n",
    "z_dim = 10\n",
    "\n",
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
    "\n",
    "def encoder(x):\n",
    "    with tf.variable_scope('Encoder', reuse=tf.AUTO_REUSE):\n",
    "        h1 = tf.layers.Dense(units=200, activation=tf.nn.relu)(x)\n",
    "        h2 = tf.layers.Dense(units=200, activation=tf.nn.relu)(h1)\n",
    "        mean = tf.layers.Dense(units=z_dim)(h2)\n",
    "        var = tf.layers.Dense(units=z_dim, activation=tf.nn.softplus)(h2)\n",
    "    return mean, var\n",
    "\n",
    "def sampling_z(mean, var):\n",
    "    epsilon = tf.random_normal(shape=tf.shape(mean))\n",
    "    z = mean + tf.sqrt(var) * epsilon\n",
    "    return z\n",
    "\n",
    "def decoder(z):\n",
    "    with tf.variable_scope('Decoder', reuse=tf.AUTO_REUSE):\n",
    "        h3 = tf.layers.Dense(units=200, activation=tf.nn.relu)(z)\n",
    "        h4 = tf.layers.Dense(units=200, activation=tf.nn.relu)(h3)\n",
    "        y = tf.layers.Dense(units=784, activation=tf.nn.sigmoid)(h4)\n",
    "    return y\n",
    "\n",
    "def lower_bound(x):\n",
    "    #Encode\n",
    "    mean, var = encoder(x)\n",
    "    KL = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + tf_log(var) - mean**2 - var, axis=1))\n",
    "    \n",
    "    #Z\n",
    "    z = sampling_z(mean, var)\n",
    "    \n",
    "    #Decode\n",
    "    y = decoder(z)\n",
    "    reconstruction = tf.reduce_mean(tf.reduce_sum(x * tf_log(y) + (1 - x) * tf_log(1 - y), axis=1))\n",
    "    \n",
    "    lower_bound = [-KL, reconstruction]\n",
    "    \n",
    "    return lower_bound\n",
    "\n",
    "\n",
    "### training ###\n",
    "#学習データと検証データに分割\n",
    "x_train, x_valid = train_test_split(x_train, test_size=0.1)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "lower_bound = lower_bound(x)\n",
    "\n",
    "cost = -tf.reduce_sum(lower_bound)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "valid = tf.reduce_sum(lower_bound)\n",
    "\n",
    "batch_size =100\n",
    "\n",
    "n_batches = x_train.shape[0] // batch_size\n",
    "n_epochs = 10\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "#for epoch in range(n_epochs):\n",
    "for epoch in range(n_epochs):\n",
    "    rng.shuffle(x_train)\n",
    "    lower_bound_all = []\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        _, lowerbound = sess.run([train, lower_bound], feed_dict={x: x_train[start:end]})\n",
    "        lower_bound_all.append(lowerbound)\n",
    "    lower_bound_all = np.mean(lower_bound_all, axis=0)\n",
    "    lower_bound_valid = sess.run(valid, feed_dict={x: x_valid[0:100]})\n",
    "    print('EPOCH:%d, Train Lower Bound:%lf, (%lf, %lf), Valid Lower Bound:%lf' %\n",
    "          (epoch+1, np.sum(lower_bound_all), lower_bound_all[0], lower_bound_all[1], lower_bound_valid))\n",
    "    \n",
    "### sampling ###\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "sample_z_func = encoder(x)\n",
    "\n",
    "z = tf.placeholder(tf.float32, [None, z_dim])\n",
    "sample_x_func = decoder(z)\n",
    "\n",
    "# Encode\n",
    "mean, var = sess.run(sample_z_func, feed_dict={x: x_test})\n",
    "sample_z = mean\n",
    "\n",
    "# Decode\n",
    "sample_x = sess.run(sample_x_func, feed_dict={z: sample_z})\n",
    "\n",
    "\n",
    "### to_csv ###\n",
    "with open('../dataset/submission.csv', 'w') as file:\n",
    "    writer = csv.writer(file, lineterminator='\\n')\n",
    "    writer.writerows(sample_x.reshape(-1, 28*28).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
